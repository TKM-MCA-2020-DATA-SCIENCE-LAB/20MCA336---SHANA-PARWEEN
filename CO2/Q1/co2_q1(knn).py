# -*- coding: utf-8 -*-
"""CO2_Q1(KNN).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s1nd06N_SlDeVPrU1nD8VRlKoApJo1UD
"""

import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv('/content/sonar_csv.csv')

df.head()

from sklearn .preprocessing import StandardScaler
sc = StandardScaler()

sc.fit(df.drop('Class',axis = 1))

s = sc.transform(df.drop('Class',axis = 1))
s

a = pd.DataFrame(s,columns = df.columns[:-1] )
a

"""**TRAINING AND TESTING:**"""

from sklearn.model_selection import train_test_split

x = a
y = df['Class']
y

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = .3,random_state=42)

from sklearn.neighbors import KNeighborsClassifier

c = KNeighborsClassifier(n_neighbors=1)

c.fit(x_train,y_train)

pred=c.predict(x_test)

from sklearn.metrics import classification_report,confusion_matrix

print(confusion_matrix(y_test,pred))
print(classification_report(y_test,pred))

#analyzing better k value through iterations.
error_rate=[]

for i in range(1,40):
  k = KNeighborsClassifier(n_neighbors=i)
  k.fit(x_train,y_train)
  pred_i= k.predict(x_test)
  error_rate.append(np.mean(pred_i!= y_test))

plt.figure(figsize=(10,6))
plt.plot(range(1,40),error_rate,color='blue',linestyle='dashed',marker='s',markerfacecolor='orange',markersize=10)
plt.title('Error Rate vs k values')
plt.xlabel('k')
plt.ylabel('Error Rate')

c = KNeighborsClassifier(n_neighbors=3)
c.fit(x_train,y_train)
pred=c.predict(x_test)
print(confusion_matrix(y_test,pred))
print(classification_report(y_test,pred))























